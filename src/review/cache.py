"""
LLM ì¿¼ë¦¬ ê²°ê³¼ë¥¼ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹±í•˜ëŠ” ëª¨ë“ˆ
"""

import hashlib
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional


def json_serializer(obj):
    """datetime ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")


class LLMQueryCache:
    """íŒŒì¼ ê¸°ë°˜ LLM ì¿¼ë¦¬ ìºì‹œ ì‹œìŠ¤í…œ"""

    def __init__(self, cache_dir: str = "cache/llm_queries", ttl_hours: int = 24):
        """
        Args:
            cache_dir: ìºì‹œ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í„°ë¦¬
            ttl_hours: ìºì‹œ ìœ ì§€ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„)
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.ttl_seconds = ttl_hours * 3600

    def _hash_reviews(self, reviews: List[Dict]) -> str:
        """
        ë¦¬ë·° ë°ì´í„°ë¥¼ í•´ì‹±í•©ë‹ˆë‹¤.
        ID + createdAt ì¡°í•©ì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì´ë©´ì„œë„ ì •í™•í•œ í•´ì‹±ì„ ì œê³µí•©ë‹ˆë‹¤.
        """
        if not reviews:
            return "empty_reviews"

        # ID + ìƒì„±ì‹œê°„ ì¡°í•©ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = []
        for review in reviews:
            review_id = review.get('id', '')
            created_at = review.get('createdAt', review.get('created_at', ''))
            metadata.append((review_id, created_at))

        # ì •ë ¬í•˜ì—¬ ìˆœì„œì— ë¬´ê´€í•˜ê²Œ ë™ì¼í•œ í•´ì‹œ ìƒì„±
        metadata.sort()
        metadata_str = json.dumps(metadata, ensure_ascii=False, default=json_serializer)

        return hashlib.md5(metadata_str.encode()).hexdigest()

    def _generate_cache_key(
            self,
            llm_name: str,
            reviews: List[Dict],
            focus_instruction: str,
            candidate_count: int
    ) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        reviews_hash = self._hash_reviews(reviews)

        # ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ í‚¤ ìƒì„±
        key_components = [
            f"llm:{llm_name}",
            f"reviews:{reviews_hash}",
            f"focus:{hashlib.md5(focus_instruction.encode()).hexdigest()}",
            f"count:{candidate_count}"
        ]

        key_string = "|".join(key_components)
        cache_key = hashlib.md5(key_string.encode()).hexdigest()

        return cache_key

    def _get_cache_file_path(self, cache_key: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return self.cache_dir / f"{cache_key}.json"

    def _is_cache_valid(self, cache_file: Path) -> bool:
        """ìºì‹œ íŒŒì¼ì´ ìœ íš¨í•œì§€ í™•ì¸ (TTL ì²´í¬)"""
        if not cache_file.exists():
            return False

        try:
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
            file_mtime = cache_file.stat().st_mtime
            current_time = time.time()

            # TTL í™•ì¸
            if current_time - file_mtime > self.ttl_seconds:
                print(f"ğŸ•’ ìºì‹œ ë§Œë£Œ: {cache_file.name}")
                return False

            return True
        except Exception as e:
            print(f"âš ï¸  ìºì‹œ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def get_cached_result(
            self,
            llm_name: str,
            reviews: List[Dict],
            focus_instruction: str,
            candidate_count: int
    ) -> Optional[List[Dict]]:
        """ìºì‹œëœ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        try:
            cache_key = self._generate_cache_key(llm_name, reviews, focus_instruction, candidate_count)
            cache_file = self._get_cache_file_path(cache_key)

            if not self._is_cache_valid(cache_file):
                return None

            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)

            # ìºì‹œ ë©”íƒ€ë°ì´í„° í™•ì¸
            if cache_data.get('version') != '1.0':
                print(f"âš ï¸  ìºì‹œ ë²„ì „ ë¶ˆì¼ì¹˜: {cache_file.name}")
                return None

            cached_result = cache_data.get('result')
            cache_info = cache_data.get('metadata', {})

            print(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {cache_key[:8]}... "
                  f"(ìƒì„±: {cache_info.get('created_at', 'unknown')})")

            return cached_result

        except Exception as e:
            print(f"âŒ ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")
            return None

    def save_result(
            self,
            llm_name: str,
            reviews: List[Dict],
            focus_instruction: str,
            candidate_count: int,
            result: List[Dict]
    ) -> None:
        """ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤"""
        try:
            cache_key = self._generate_cache_key(llm_name, reviews, focus_instruction, candidate_count)
            cache_file = self._get_cache_file_path(cache_key)

            # ìºì‹œ ë°ì´í„° êµ¬ì„±
            cache_data = {
                'version': '1.0',
                'metadata': {
                    'cache_key': cache_key,
                    'created_at': datetime.now().isoformat(),
                    'llm_name': llm_name,
                    'reviews_count': len(reviews),
                    'candidate_count': candidate_count,
                    'focus_hash': hashlib.md5(focus_instruction.encode()).hexdigest()[:8]
                },
                'result': result
            }

            # ì›ìì  ì“°ê¸° (ì„ì‹œ íŒŒì¼ ì‚¬ìš©)
            temp_file = cache_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, default=json_serializer)

            # ì„ì‹œ íŒŒì¼ì„ ì‹¤ì œ ìºì‹œ íŒŒì¼ë¡œ ì´ë™
            temp_file.rename(cache_file)

            print(f"ğŸ’¾ ìºì‹œ ì €ì¥: {cache_key[:8]}... "
                  f"(ë¦¬ë·°: {len(reviews)}ê°œ, LLM: {llm_name})")

        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def clear_expired_cache(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ íŒŒì¼ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤"""
        cleared_count = 0
        try:
            for cache_file in self.cache_dir.glob("*.json"):
                if not self._is_cache_valid(cache_file):
                    cache_file.unlink()
                    cleared_count += 1

            if cleared_count > 0:
                print(f"ğŸ§¹ ë§Œë£Œëœ ìºì‹œ {cleared_count}ê°œ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

        return cleared_count

    def get_cache_info(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            valid_files = [f for f in cache_files if self._is_cache_valid(f)]
            expired_files = [f for f in cache_files if not self._is_cache_valid(f)]

            total_size = sum(f.stat().st_size for f in cache_files)

            return {
                'cache_dir': str(self.cache_dir),
                'total_files': len(cache_files),
                'valid_files': len(valid_files),
                'expired_files': len(expired_files),
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'ttl_hours': self.ttl_seconds / 3600
            }

        except Exception as e:
            print(f"âŒ ìºì‹œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}


# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
_cache_instance = None


def get_cache() -> LLMQueryCache:
    """ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = LLMQueryCache()
    return _cache_instance


def clear_cache() -> int:
    """ì „ì—­ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"""
    cache = get_cache()
    return cache.clear_expired_cache()


def get_cache_stats() -> Dict[str, Any]:
    """ìºì‹œ í†µê³„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    cache = get_cache()
    return cache.get_cache_info()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    cache = LLMQueryCache()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_reviews = [
        {'id': 1, 'text': 'Great product!', 'createdAt': '2024-01-01'},
        {'id': 2, 'text': 'Amazing quality', 'createdAt': '2024-01-02'}
    ]

    test_result = [
        {'id': 1, 'score': 95, 'text': 'Great product!'}
    ]

    # ìºì‹œ ì €ì¥ í…ŒìŠ¤íŠ¸
    cache.save_result(
        llm_name="gpt-3.5-turbo",
        reviews=test_reviews,
        focus_instruction="Select best reviews",
        candidate_count=3,
        result=test_result
    )

    # ìºì‹œ ì½ê¸° í…ŒìŠ¤íŠ¸
    cached = cache.get_cached_result(
        llm_name="gpt-3.5-turbo",
        reviews=test_reviews,
        focus_instruction="Select best reviews",
        candidate_count=3
    )

    print("ìºì‹œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:", cached)
    print("ìºì‹œ ì •ë³´:", cache.get_cache_info())
